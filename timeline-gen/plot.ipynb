{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf6fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import turtle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c598a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global vars\n",
    "DATA_FILE_JSON = \"data.json\"\n",
    "DATA_FILE_SUMMARY = \"summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d01c8ee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the summary to identify files to follow\n",
    "#\n",
    "# Assumes summary format is in this order\n",
    "#     trivial:    -> all trivial moves\n",
    "#                 order of:\n",
    "#                     job [src_level]->[dest_level] [src_table]->[dest_table]\n",
    "#                     R: [zone_resets]\n",
    "#     flush:      -> all flushes\n",
    "#                 order of:\n",
    "#                     job [table]\n",
    "#                     R: [zone_resets]\n",
    "#     compaction: -> all compactions\n",
    "#                 order of:\n",
    "#                     job src_level->dest_level [src_tables] | [merge_tables] -> [dest_tables] \n",
    "#                     D: [table_deletes]\n",
    "#                     R: [zone_resets]\n",
    "\n",
    "summary_dict = dict()\n",
    "\n",
    "with open(DATA_FILE_SUMMARY) as sum_file:\n",
    "    trivial = False\n",
    "    flush = False\n",
    "    compaction = False\n",
    "    summary_dict[\"trivial\"] = dict()\n",
    "    summary_dict[\"flush\"] = dict()\n",
    "    summary_dict[\"compaction\"] = dict()\n",
    "    job_stack = []\n",
    "\n",
    "    \n",
    "    for line in sum_file:\n",
    "        if trivial:\n",
    "            if \"flush:\" in line:\n",
    "                trivial = False\n",
    "                flush = True\n",
    "            else:\n",
    "                line_split = line.split()\n",
    "                if \"R\" in line:\n",
    "                    summary_dict[\"trivial\"][job_stack.pop()][\"resets\"] = eval(line[line.find(\"[\"):line.find(\"]\")+1])\n",
    "                else:\n",
    "                    job = line_split[0]\n",
    "                    summary_dict[\"trivial\"][job] = dict()\n",
    "                    job_stack.append(job)\n",
    "                    levels = list(map(int, re.findall(r'\\d+', line_split[1])))\n",
    "                    summary_dict[\"trivial\"][job][\"src_level\"] = levels[0] \n",
    "                    summary_dict[\"trivial\"][job][\"dest_level\"] = levels[1]\n",
    "\n",
    "                    # Tables are identical as the moves are trivial\n",
    "                    tables = line[line.find(\"[\"):line.find(\"]\")+1]\n",
    "                    summary_dict[\"trivial\"][job][\"tables\"] = eval(tables)\n",
    "            \n",
    "        elif flush:\n",
    "            if \"compaction:\" in line:\n",
    "                flush = False\n",
    "                compaction = True\n",
    "            else:\n",
    "                line_split = line.split()\n",
    "                if \"R\" in line:\n",
    "                    summary_dict[\"flush\"][job_stack.pop()][\"resets\"] = eval(line[line.find(\"[\"):line.find(\"]\")+1])\n",
    "                else:\n",
    "                    job = line_split[0]\n",
    "                    job_stack.append(job)\n",
    "                    summary_dict[\"flush\"][job] = dict()\n",
    "                    summary_dict[\"flush\"][job][\"table\"] = int(line[line.find(\"[\")+2:line.find(\"]\")-1]) # strip the ' char\n",
    "\n",
    "        elif compaction:\n",
    "            line_split = line.split()\n",
    "\n",
    "            if \"R\" in line:\n",
    "                summary_dict[\"compaction\"][job_stack.pop()][\"resets\"] = \\\n",
    "                    eval(line[line.find(\"[\"):line.find(\"]\")+1])\n",
    "            elif \"D\" in line:\n",
    "                job = job_stack.pop()\n",
    "                job_stack.append(job)\n",
    "                summary_dict[\"compaction\"][job][\"resets\"] = \\\n",
    "                    eval(line[line.find(\"[\"):line.find(\"]\")+1])\n",
    "            else:\n",
    "                job = line_split[0]\n",
    "                summary_dict[\"compaction\"][job] = dict()\n",
    "                job_stack.append(job)\n",
    "                levels = list(map(int, re.findall(r'\\d+', line_split[1])))\n",
    "                summary_dict[\"compaction\"][job][\"src_level\"] = levels[0] \n",
    "                summary_dict[\"compaction\"][job][\"dest_level\"] = levels[1]\n",
    "                table_split = line.split(\"|\")\n",
    "                src_tables = line[table_split[0].find(\"[\"):table_split[0].find(\"]\")+1]\n",
    "                summary_dict[\"compaction\"][job][\"src_tables\"] = eval(src_tables)\n",
    "                info = table_split[1].split(\"->\")\n",
    "                summary_dict[\"compaction\"][job][\"merge_tables\"] = eval(info[0])\n",
    "                summary_dict[\"compaction\"][job][\"dest_tables\"] = eval(info[1])\n",
    "\n",
    "        if \"trivial:\" in line:\n",
    "            trivial = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6fecc818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the json data\n",
    "file = open(DATA_FILE_JSON) \n",
    "json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057703b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b8210dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configuration variables for plotting\n",
    "\n",
    "MAX_TIMEUNITS = 2 # Set the number of time units to show (i.e., operations; flush, compaction, trivial, F2FS GC)\n",
    "TRACE_FILE = 15 # Number of the SST file to trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3f9205df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zone:\n",
    "    def __init__(self, zone, temperature, status, file):\n",
    "        self.zone = zone\n",
    "        self.temperature = temperature\n",
    "        self.status = status # Valid, Invalid, Reset\n",
    "        self.files = []\n",
    "        self.files.append(file)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"Zone Number: {self.zone}, Temp: {self.temperature}, Status: {self.status}, Files: {self.files}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "64d60648",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeUnit:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.zones = []\n",
    "        \n",
    "    def __str__(self):\n",
    "        msg = f\"Total Zones: {len(self.zones)}\\n\"\n",
    "        for zone in self.zones:\n",
    "            msg += str(zone)\n",
    "        return msg\n",
    "    \n",
    "    def addzone(self, zoneid, temperature, status, file):\n",
    "        self.zones.append(Zone(zoneid, temperature, status, file))\n",
    "        \n",
    "    def haszone(self, zoneid):\n",
    "        for zone in self.zones:\n",
    "            if zoneid == zone.zone:\n",
    "                return True\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ad50d165",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Zones: 4\n",
      "Zone Number: 5, Temp: CURSEG_COLD_DATA, Status: Valid, Files: ['21']\n",
      "Zone Number: 8, Temp: CURSEG_HOT_DATA, Status: Valid, Files: ['21']\n",
      "Zone Number: 10, Temp: CURSEG_COLD_DATA, Status: Valid, Files: ['21']\n",
      "Zone Number: 11, Temp: CURSEG_COLD_DATA, Status: Valid, Files: ['22']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timeline = []\n",
    "timectr = 0\n",
    "\n",
    "for i in range(MAX_TIMEUNITS):    \n",
    "    for op, item in summary_dict.items():\n",
    "        if op == \"flush\":\n",
    "            for job, data in item.items():\n",
    "                if TRACE_FILE == data[\"table\"]:\n",
    "                    timeline.append(TimeUnit(timectr))\n",
    "                    \n",
    "                    # find the zone in the operation\n",
    "                    for entry in json_data[job][\"f2fs_file_snapshot_after\"]:\n",
    "                        if f\"0{TRACE_FILE}.sst\" in entry[\"filename\"]:\n",
    "                            for zone in entry[\"hint\"]:\n",
    "                                if not timeline[timectr].haszone(zone[0]):\n",
    "                                    timeline[timectr].addzone(zone[0], zone[1], \"Valid\", TRACE_FILE)\n",
    "                    timectr+=1\n",
    "    \n",
    "        if op == \"compaction\":\n",
    "            for job, data in item.items():\n",
    "                if TRACE_FILE in data[\"src_tables\"]:\n",
    "                    timeline.append(TimeUnit(timectr))\n",
    "                    for destination in data[\"dest_tables\"]:\n",
    "                    \n",
    "                        # find the zone in the operation\n",
    "                        for entry in json_data[job][\"f2fs_file_snapshot_after\"]:\n",
    "                            if f\"0{destination}.sst\" in entry[\"filename\"]:\n",
    "                                for zone in entry[\"hint\"]:\n",
    "                                    if not timeline[timectr].haszone(zone[0]):\n",
    "                                        timeline[timectr].addzone(zone[0], zone[1], \"Valid\", destination)\n",
    "                    timectr+=1\n",
    "print(timeline[1])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f870a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d723ce6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f6eaf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
